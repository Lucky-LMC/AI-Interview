import os
import asyncio
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent
from dotenv import load_dotenv

load_dotenv("backend/config/.env")

async def test_agent_no_tools():
    print("\n" + "="*60)
    print("2. Agent åŒ…è£…æµ‹è¯• (æ— å·¥å…·, Kimi-Dev-72B)")
    print("="*60)
    
    api_key = "ms-e714a9a5-5652-47f2-8d94-8459a6152b59"
    model_name = "deepseek-ai/DeepSeek-R1-Distill-Llama-8B"
    base_url = "https://api-inference.modelscope.cn/v1"
    
    llm = ChatOpenAI(
        model=model_name,
        base_url=base_url,
        api_key=api_key,
        temperature=0.7,
        extra_body={"chat_template_kwargs": {"enable_thinking": True}}
    )
    
    # åˆ›å»º Agentï¼Œä¸æä¾›å·¥å…·
    agent = create_react_agent(llm, tools=[], prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¢è¯•å®˜ã€‚")
    
    inputs = {"messages": [("user", "ä½œä¸ºé«˜çº§åç«¯å·¥ç¨‹å¸ˆï¼Œä½ æœ€çœ‹é‡å€™é€‰äººçš„å“ªäº›ç´ è´¨ï¼Ÿ")]}
    
    print(f"æ­£åœ¨è¿è¡Œ Agent: {model_name}...")
    result = await agent.ainvoke(inputs)
    
    # è·å–æœ€åä¸€æ¡ AI æ¶ˆæ¯
    last_msg = result["messages"][-1]
    content = last_msg.content
    
    if "</think>" in content:
        parts = content.split("</think>")
        thinking = parts[0].replace("<think>", "").strip()
        answer = parts[1].strip()
        print("\nğŸ§  ã€Agent å†…éƒ¨æ€è€ƒã€‘:")
        print("-" * 40)
        print(thinking)
        print("\nğŸ’¬ ã€Agent æœ€ç»ˆå›å¤ã€‘:")
        print("-" * 40)
        print(answer)
    else:
        print("\nğŸ’¬ ã€Agent å›å¤ã€‘:")
        print("-" * 40)
        print(content)

if __name__ == "__main__":
    asyncio.run(test_agent_no_tools())
