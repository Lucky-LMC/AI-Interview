import os
import asyncio
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent
from dotenv import load_dotenv

load_dotenv("backend/config/.env")

@tool
def get_weather(city: str):
    """è·å–æŒ‡å®šåŸå¸‚çš„å®æ—¶å¤©æ°”"""
    return f"{city}ä»Šå¤©æ™´ï¼Œ25åº¦ã€‚"

async def test_agent_with_tools():
    print("\n" + "="*60)
    print("3. Agent åŒ…è£…æµ‹è¯• (å¸¦å·¥å…·, Kimi-Dev-72B)")
    print("="*60)
    
    api_key = os.getenv("OPENAI_API_KEY")
    base_url = os.getenv("OPENAI_API_BASE")
    model_name = "moonshotai/Kimi-Dev-72B"
    
    llm = ChatOpenAI(
        model=model_name,
        base_url=base_url,
        api_key=api_key,
        temperature=0.7,
        extra_body={"chat_template_kwargs": {"enable_thinking": True}}
    )
    
    # åˆ›å»º Agentï¼Œæä¾›å·¥å…·
    agent = create_react_agent(llm, tools=[get_weather], prompt="ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚")
    
    inputs = {"messages": [("user", "åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")]}
    
    print(f"æ­£åœ¨è¿è¡Œ Agent: {model_name}...")
    result = await agent.ainvoke(inputs)
    
    print("\n" + "="*40)
    print("æ¶ˆæ¯æµåˆ†æ:")
    print("="*40)
    
    for msg in result["messages"]:
        print(f"\nã€{msg.type.upper()}ã€‘:")
        content = msg.content
        if "</think>" in content:
            parts = content.split("</think>")
            thinking = parts[0].replace("<think>", "").strip()
            answer = parts[1].strip()
            print(f"ğŸ§  æ€è€ƒ: {thinking[:200]}...")
            print(f"ğŸ’¬ å›å¤: {answer}")
        else:
            print(content)
        
        if hasattr(msg, "tool_calls") and msg.tool_calls:
            print(f"ğŸ› ï¸ å·¥å…·è°ƒç”¨: {msg.tool_calls[0]['name']}")

if __name__ == "__main__":
    asyncio.run(test_agent_with_tools())
